#
# This schedule performs 3D (filter-wise) regularization of some of the convolution layers, together with
# element-wise pruning using sensitivity-pruning.
#
# time python3 compress_classifier.py -a=vgg19 -p=50 ../../../data.imagenet --epochs=10 --lr=0.00001 --compress=../pruning_filters_for_efficient_convnets/vgg19.schedule_filter_rank.yaml --pretrained
#


version: 1
pruners:
  vgg_80:
    class: 'L1RankedStructureParameterPruner'
    group_type: Filters
    desired_sparsity: 0.8
    weights: [
              features.module.0.weight,
              ]

  vgg_50:
    class: 'L1RankedStructureParameterPruner'
    group_type: Filters
    desired_sparsity: 0.5
    weights: [
              features.module.3.weight,
              features.module.7.weight,
              ]

  vgg_25:
    class: 'L1RankedStructureParameterPruner'
    group_type: Filters
    desired_sparsity: 0.25
    weights: [
              features.module.14.weight,
              features.module.17.weight,
              ]


  vgg_20:
    class: 'L1RankedStructureParameterPruner'
    group_type: Filters
    desired_sparsity: 0.2
    weights: [
              features.module.20.weight,
              features.module.23.weight,
              ]

  vgg_15:
    class: 'L1RankedStructureParameterPruner'
    group_type: Filters
    desired_sparsity: 0.15
    weights: [
              features.module.10.weight,
              features.module.30.weight,
              ]

  vgg_10:
    class: 'L1RankedStructureParameterPruner'
    group_type: Filters
    desired_sparsity: 0.10
    weights: [
              features.module.27.weight,
              ]

  vgg_05:
    class: 'L1RankedStructureParameterPruner'
    group_type: Filters
    desired_sparsity: 0.05
    weights: [
              features.module.33.weight,
              features.module.36.weight,
              features.module.49.weight,
              ]


extensions:
  net_thinner:
      class: 'FilterRemover'
      thinning_func_str: remove_filters
      arch: 'vgg19_bn'
      dataset: 'imagenet'

lr_schedulers:
  # Learning rate decay scheduler
  pruning_lr:
    class: StepLR
    step_size: 50
    gamma: 0.10


policies:
  - pruner:
      instance_name: vgg_80
    epochs: [0]

  # - pruner:
  #     instance_name: vgg_50
  #   epochs: [5]

  # - pruner:
  #     instance_name: vgg_25
  #   epochs: [0]

  # - pruner:
  #     instance_name: vgg_20
  #   epochs: [0]

  # - pruner:
  #     instance_name: vgg_15
  #   epochs: [0]

  # - pruner:
  #     instance_name: vgg_10
  #   epochs: [0]

  # - pruner:
  #     instance_name: vgg_05
  #   epochs: [0]

  - extension:
      instance_name: net_thinner
    epochs: [9]

  - lr_scheduler:
      instance_name: pruning_lr
    starting_epoch: 0
    ending_epoch: 20
    frequency: 1
